\chapter{Introducción}

\section{Contexto}

En el entorno de la imagen generada por computador siempre ha sido un reto tratar de generar imágenes lo más realistas posibles. Para ello un gran número de investigadores se han dedicado a diseñar algoritmos que simulan o imitan el comportamiento y la interacción de la luz con los materiales. Estos algoritmos que tratan de simular de forma realista el comportamiento de la luz son generalmente conocidos como algoritmos de iluminación global.

\medskip

Estos algoritmos, por lo general, suelen tener una complejidad computacional muy elevada y el tiempo de cómputo necesario para obtener un resultado satisfactorio en escenas complejas era un factor limitador en su aplicación práctica. Por ello las aplicaciones que hacen uso de gráficos 3D en tiempo real típicamente se centran en la iluminación local o directa de los objetos de la escena y simulan la iluminación indirecta mediante técnicas que aun sin tener un fundamento físico ofrecen una mayor credibilidad para el ojo humano. Estas técnicas suelen ser algoritmos de postprocesado que se aplican en espacio de pantalla, por ejemplo \emph{ambient occlusion} o \emph{directional occlusion}. 

\medskip

Sin embargo en los últimos años se han realizado grandes avances en las arquitecturas de las unidades de procesamiento de gráficos (GPUs), en especial la gran capacidad de cómputo en paralelo debido al elevado número de microprocesadores que forman estos dispositivos. Con tal de aprovechar estos avances en el hardware los fabricantes de GPU han desarrollado librerías de computo genérico (OpenCL, CUDA), que ofrecen gran libertad al programador para implementar sus propios algoritmos.

\medskip

Estas mejoras han permitido realizar implementaciones de algoritmos de iluminación global en las GPUs que son mucho más rápidos que las implementaciones típicas en la CPU, permitiendo reducir el tiempo de cómputo de varias horas o días a minutos e incluso a tiempos interactivos dependiendo de la GPU y algoritmos utilizados.

\clearpage

\section{Algoritmos de iluminación global}

Se conoce como algoritmos de iluminación global aquellos que tratan de simular distintos aspectos del comportamiento de la luz en su interacción con los objetos de una escena tridimensional. Algunos de ellos están pensados y optimizados para fenómenos concretos, mientras que otros tratan de recrear fielmente todos los aspectos del transporte de luz.

\medskip
En esta sección revisaremos por encima algunos de los algoritmos clásicos. Téngase en cuenta que no es el objetivo de este trabajo hacer un análisis exhaustivo de todos los algoritmos ni dar una explicación detallada de cada uno de ellos. Si el lector desea mas información sobre alguno de ellos, se han citado las fuentes originales a las que puede remitirse.

\subsection{Ray tracing}

Aunque no se trata de un algoritmo de iluminación global propiamente dicho, el algoritmo de ray tracing original, desarrollado primeramente por Appel (1968)\nocite{Appel1968} y posteriormente ampliado en \cite{Whitted1979}, es relevante por la influencia que ha tenido en el campo de los gráficos generados por computador y por que ha servido de base para métodos de iluminación global desarrollados posteriormente. 

\medskip

En este algoritmo se lanzan rayos desde la cámara a través de los pixels de la pantalla y se comprueba si interseccionan con los objetos de la escena. En la versión de Whitted además se lanzan rayos recursivamente si el objeto es reflectante o refractante y hacia las luces, para comprobar si al objeto le llega luz directamente.

 
\subsection{Radiosity}

Radiosity fue el primero de los algoritmos de iluminación global que se desarrollaron. Inicialmente el algoritmo fue desarrollado en los años 1950 para aplicarlo al problema de la transferencia de calor. En 1984 fue modificado y adaptado por \nocite{Goral1984} Cindy M. Goral, Kenneth E. Torrance, Donald P. Greenberg y Bennett Battaile, investigadores de la universidad de Cornell para su aplicación en la generación de imagen sintética.

\medskip

Este algoritmo trata de resolver el problema de la iluminación indirecta entre superficies puramente difusas sin tomar en cuenta la reflectancia especular.

\medskip

El funcionamiento del algoritmo, en lineas generales, se basa en dividir la escena en pequeñas unidades de área, llamadas parches, que deberían funcionar como diferenciales de área. Luego a través de una serie de iteraciones se intenta balancear el flujo de luz emitido, reflejado y absorbido entre todos estos parches.

\clearpage

\subsection{Path tracing}

El algoritmo de path tracing \cite{Kajiya1986} sea posiblemente el primer algoritmo capaz de solucionar completamente la ecuación de renderizado.

\medskip

Este algoritmo empieza como el ray tracing clásico, lanzando rayos desde la cámara hacia la escena, pero cuando un rayo intersecciona con un objeto se lanza un rayo en una dirección aleatoria para tener una estimación de cuanta luz indirecta llega a ese punto. Este rayo aleatorio, a su vez es evaluado recursivamente siguiendo el mismo procedimiento. 

\medskip 

Evidentemente este proceso de trazar un rayo desde la cámara y hacerlo rebotar por la escena para obtener un estimación de la luz es muy impreciso, por lo que es necesario repetir el proceso varias veces, y hacer la media entre los resultados obtenidos para obtener una solución satisfactoria. 

\subsection{Bidirectional path tracing}

El algoritmo de Bidirectional path tracing \cite{Lafortune1993} fue desarrollado como una extensión al algoritmo de path tracing de Kajiya. En esta modalidad los rayos primarios no solo se lanzan desde la cámara, sino también desde las fuentes de luz. Estos caminos de luz, se calculan del mismo modo que los de la cámara. Se guardan los puntos de intersección de los caminos de la cámara y los de la luz y en una ultima fase se unen estos dos grupos de puntos para obtener la evaluación final del camino.

\medskip
La principal mejora de este algoritmo respecto a su antecesor, es que es capaz de funcionar mejor y converger mas rápido hacia una solución correcta en escenas complejas, en las que las fuentes de luz no son fácilmente visibles desde la mayoría de puntos de la escena.

\subsection{Metropolis light transport}

Siguiendo en la linea de los dos algoritmos anteriores, otra notable mejora llego con el llamado Metropolis light transport \cite{Veach1997}. Este algoritmo parte de la base del path tracing bidireccional, pero en vez de confiar en crear muchos paths hasta converger a una solución aceptable, utiliza un método conocido como algoritmo de Metropolis-Hastings para generar varias mutaciones del mismo path. 

\medskip
Este algoritmo desata todo su potencial cuando se trata de renderizar interacciones complejas entre materiales, que normalmente serian muy costosas de renderizar con los algoritmos que hemos comentado anteriormente. Por ejemplo cáusticas, intereflexiones especulares-difusas, etc.

\clearpage

\subsection{Photon mapping}

Todos los algoritmos que estamos viendo tratan la luz como partículas y no como ondas, pero este algoritmo lo hace de un modo aun mas explicito.
El algoritmo de Photon mapping \cite{Jensen1996} empieza lanzando rayos (fotones) desde las fuentes de luz. Cuando estos fotones interseccionan con un objeto de la escena se decide aleatoriamente y según las propiedades (BRDF) del material si el fotón sera absorbido, dispersado especularmente o dispersado difusamente. Las posiciones finales donde los fotones son absorbidos se guardan en un mapa (kd-tree) de fotones para la siguiente fase.

\medskip
La siguiente fase, llamada final gathering, realiza un ray tracing de la escena y en cada intersección consulta el mapa de fotones para ver la cantidad de luz que llega a ese punto.

\medskip
Este algoritmo sobresale entre todos los demás cuando se trata de renderizar cáusticas, pero en cambio, puede producir errores cuando se renderizan superficies difusas si el numero de fotones no es muy grande.


\subsection{Instant radiosity}

Este algoritmo, desarrollado por Keller en 1997 \nocite{Keller1997}, combina las ideas de los algoritmos de radiosity y photon mapping. Igual que el radiosity original, este algoritmo, en principio, solo funciona para superficies puramente difusas.

\medskip
La idea general consiste en lanzar fotones desde las fuentes de luz (como en photon mapping) e ir guardando sus posiciones. La diferencia principal radica en que en la fase de renderizado, estos fotones son tratados como luces puntuales (VPLs, del inglés Virtual Point Lights) con orientación, es decir que tienen un vector normal. La ventaja es que una vez generados estos VPL es posible renderizar la escena mediante una API gráfica tradicional acelerada por hardware, como OpenGL o DirectX, o con ray tracing.

\medskip

Además del algoritmo de instant radiosity básico existen modificaciones del mismo que combinan las ideas de los algoritmos de path tracing con el de instant radisioty. En este conjunto de algoritmos encontramos el instant radiosity bidireccional y el metropolis instant radiosity.  


\clearpage

\section{Tecnologías involucradas}

El propósito de esta sección es explicar las principales tecnologías utilizadas durante el desarrollo de este proyecto. Debido al alcance de este trabajo la mayoría de tecnologías que comentaremos en este apartado son tecnologías especificas de las GPU.

\subsection{Arquitectura de las GPU modernas}

Las arquitecturas de GPU modernas siguen una paradigma conocido como SIMD (del inglés, Single Instruction Multiple Data), que consiste en la capacidad de un procesador de ejecutar la misma instrucción en paralelo sobre datos distintos. Es decir, que se ejecuta el mismo proceso en varias unidades de computo, pero los datos que trata cada unidad pueden ser distintos.

\subsection{Shaders}

Los fabricantes de GPUs empezaron a explotar esta capacidad de computo en paralelo, ofreciendo a los programadores de gráficos la posibilidad de programar ciertos puntos del proceso de renderizado efectuado por las GPU, con los llamados shaders. Los shaders son pequeños programas que se ejecutan en la GPU y sirven para programar funcionalidades. Tradicionalmente existían dos tipos de shaders: los vertex shaders, que se ejecutaban para cada vértice de cada primitiva a pintar, y los pixel o fragment shaders que se ejecutaban para cada pixel rasterizado.

\medskip
Según el paradigma SIMD, solo puede ejecutarse un único shader en cada GPU pero los datos pueden ser distintos: en el caso de los vertex shaders, por ejemplo, cada unidad de procesamiento tendrá acceso a las coordenadas geométricas de un vértice, las coordenadas de textura de ese vértice, etc. Es decir que un vertex shader ejecutara exactamente las mismas operaciones para cada vértice en paralelo. 

\clearpage

\subsection{Capacidad de computo genérico}
La principal limitación de los shaders es que solo trabajan con datos relacionados con el renderizado de gráficos (coordenadas de vértices, coordenadas de textura, vectores normales, texturas, etc). Si un programador quería utilizar la capacidad de computo en paralelo de las GPU para problemas distintos al renderizado por rasterizado de gráficos, debía buscar la manera de codificar los datos del problema en forma de vértices y texturas, lo cual podía resultar tedioso o complicado.

\medskip
Debido a esta necesidad los fabricantes de GPU empezaron a buscar una forma de ampliar las capacidades de computo que ofrecían sus dispositivos y desarrollaron plataformas de programación genérica en GPUs. La primera de estas plataformas fue la desarrollada por Nvidia, con el nombre CUDA, para sus tarjetas gráficas. Posteriormente se desarrollo OpenCL, un estándar de computo en paralelo tanto para GPUs, como para CPUs, soportado por la mayoría de fabricantes de hardware.

\subsection{CUDA}

CUDA es la plataforma de computo genérico sobre GPU desarrollada por Nvidia para GPUs de Nvidia. El compilador nvcc (NVidia C Compiler) permite tanto compilar programas con una parte en el host (CPU) y otra parte en el device (la GPU), como compilar kernels, que se ejecutaran en la GPU.

\subsection{OptiX}

OptiX es una librería de ray tracing sobre CUDA desarrolada por Nvidia. Optix esta diseñado con la idea de ofrecer un framework para ray tracing lo más genérico y programable posible, tratando de no limitar las posibilidades del programador.

\clearpage

\section{Objetivos}

El principal objetivo de este trabajo es realizar una implementación de un algoritmo de iluminación global, lo más completo posible, usando tecnologías de GPU para aprovechar las ventajas que ofrecen estos dispositivos en cuanto a tiempo de ejecución.

\medskip

Para ello, un primer objetivo necesario era estudiar los distintos algoritmos y decidir cual se adaptaba mejor al objetivo de este trabajo, tomando en cuenta la completitud del mismo, es decir, cuan realistas son los resultados ofrecidos por el algoritmo. Otro factor importante en la decisión del algoritmo a utilizar es que sea paralelizable, factor indispensable para poder realizar una implementación eficiente en la GPU.

\medskip

Una vez decidido el algoritmo, otro objetivo parcial necesario para alcanzar el objetivo primario es realizar un estudio teórico detallado del algoritmo en cuestión, y de las técnicas y conceptos relacionados con el mismo, con tal de tener una comprensión de este lo bastante profunda como para realizar una implementación seria.

\medskip

Finalmente sera necesario plasmar los conocimientos teóricos adquiridos en una implementación de un renderizador con iluminación global. 




